
lib
---

- timeout searches (use periodic timer and start date for each search)

- notify search manager of new sessions and resend searches until
  AS_SEARCH_SEND_COUNT is reached.

- Add timer to download which regularly calls download_maintain in order to
  the status of remotely queued sources.

- Add AS_DOWNLOAD_MAX_ACTIVE_SOURCES which limits the number of active sources
  per download.

- Calculate average bandwidth for sources and use faster ones during end game.
  Generally sort connection list by b/w so faster ones are always used first.

- Make file hashing non-blocking.

- Create sources from X-Alt headers and add them

- Check how Ares handles same file names for downloads and do the same.
  Reverse _ARESTRA_ file appendix.

- Parse node list packet

- Does persisten http actually work? It seems remote closes connection on
  second request.
  Update: Saw it working a few times. So is it a remote problem?